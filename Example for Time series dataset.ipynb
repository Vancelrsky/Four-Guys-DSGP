{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c056a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# this method take a dataframe as input, return the feature part and label part\n",
    "def parse_header_of_csv(csv_df):\n",
    "    # Isolate the headline columns:\n",
    "\n",
    "    for (ci,col) in enumerate(csv_df.columns):\n",
    "        # find the start of label column\n",
    "            if col.startswith('label:'):\n",
    "                first_label_ind = ci\n",
    "                break\n",
    "            pass\n",
    "    # use the \"start of label\" find above to split feature and label\n",
    "    feature_names = csv_df.columns[1:first_label_ind]\n",
    "    label_names = list(csv_df.columns[first_label_ind:-1])\n",
    "\n",
    "    # remove \"label: \" get pure label name\n",
    "    for (li,label) in enumerate(label_names):\n",
    "    # In the CSV the label names appear with prefix 'label:', but we don't need it after reading the data:\n",
    "            assert label.startswith('label:')\n",
    "            label_names[li] = label.replace('label:','')\n",
    "            pass\n",
    "\n",
    "    csv_df.rename(columns=dict(zip(csv_df.columns[first_label_ind:-1],label_names)),inplace=True)\n",
    "        \n",
    "    return (feature_names,label_names)\n",
    "\n",
    "\"\"\"\n",
    "this method take a dataframe and number of features as input, \n",
    "return sensor matrix, label matrix, missing label matrix and timestamp matrix(index)\n",
    "\"\"\"\n",
    "def parse_body_of_csv(csv_df,n_features):\n",
    "\n",
    "\n",
    "    # Read the entire CSV body into a single numeric matrix:\n",
    "    \n",
    "    # Timestamp is the primary key for the records (examples):\n",
    "    timestamps = csv_df.index\n",
    "    # Read the sensor features:\n",
    "    X = csv_df[csv_df.columns[0:n_features+1]]\n",
    "    # Read the binary label values, and the 'missing label' indicators:\n",
    "    trinary_labels_mat = csv_df[csv_df.columns[n_features+1:-1]] # This should have values of either 0., 1. or NaN\n",
    "\n",
    "    M = pd.isna(trinary_labels_mat) # M is the missing label matrix\n",
    "    Y = np.where(M,0,trinary_labels_mat) > 0. # Y is the label matrix\n",
    "\n",
    "    \n",
    "    return (X,Y,M,timestamps)\n",
    "\n",
    "'''\n",
    "Read the data (precomputed sensor-features and labels) for a user.\n",
    "This function assumes the user's data file is present.\n",
    "this method take id of subject as input\n",
    "return sensor matrix, label matrix, missing label matrix and timestamp matrix(index) by calling parse_body_of_csv()method\n",
    "\n",
    "'''\n",
    "def read_user_data(uuid):\n",
    "    # user_data_file = '%s.features_labels.csv.gz' % uuid\n",
    "    user_data_file = os.path.join('Dataset', '%s.features_labels.csv.gz' % uuid)\n",
    "\n",
    "    with gzip.open(user_data_file,'rb') as fid:\n",
    "        csv_df = pd.read_csv(fid,delimiter=',', index_col= 0)\n",
    "        pass\n",
    "\n",
    "    (feature_names,label_names) = parse_header_of_csv(csv_df)\n",
    "    n_features = len(feature_names)\n",
    "    (X,Y,M,timestamps) = parse_body_of_csv(csv_df,n_features)\n",
    "\n",
    "    return (X,Y,M,timestamps,feature_names,label_names)\n",
    "\n",
    "\n",
    "uuid_list = []\n",
    "f = open('Dataset/UUID List.txt', 'r')\n",
    "for line in f.readlines():\n",
    "    uuid_list.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('cleaned_data.zip','rb')as file:\n",
    "    cleaned_data = pd.read_csv(file, index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_label_list = [['SLEEPING'],\n",
    "                   ['LAB_WORK', 'IN_CLASS', 'IN_A_MEETING', 'LOC_main_workplace','COMPUTER_WORK','AT_SCHOOL', 'WITH_CO-WORKERS'],\n",
    "                   ['FIX_walking', 'FIX_running', 'BICYCLING','OR_exercise'],\n",
    "                   ['COOKING', 'BATHING_-_SHOWER', 'CLEANING', 'DOING_LAUNDRY', 'WASHING_DISHES', 'EATING', 'TOILET', 'GROOMING', 'DRESSING'],\n",
    "                   ['FIX_restaurant','SHOPPING', 'STROLLING', 'DRINKING__ALCOHOL_','WATCHING_TV', 'SURFING_THE_INTERNET', 'AT_A_PARTY', 'AT_A_BAR', 'LOC_beach', 'SINGING', 'WITH_FRIENDS'],                   \n",
    "                   ['IN_A_CAR', 'ON_A_BUS', 'DRIVE_-_I_M_THE_DRIVER', 'DRIVE_-_I_M_A_PASSENGER','STAIRS_-_GOING_DOWN', 'ELEVATOR']]\n",
    "\n",
    "new_label_list = ['sleep','efficiency','exercise','life_activity','entertainment','on_the_way']\n",
    "new_label_dict = {'sleep':0, 'efficiency':1, 'exercise':2, 'life_activity':3, 'entertainment':4, 'on_the_way':5, 'Normal':6}\n",
    "\n",
    "all_label_list = []\n",
    "\n",
    "for i in main_label_list:\n",
    "    all_label_list = all_label_list + i\n",
    "\n",
    "  \n",
    "new_label_data = pd.DataFrame()\n",
    "for uuid in cleaned_data.groupby('uuid').count().index:\n",
    "    X,Y,M,timestamps,feature_names,label_names = read_user_data(uuid)\n",
    "    label_pair = pd.DataFrame(\n",
    "        columns = ['Label Name'],\n",
    "        index = timestamps\n",
    "    )\n",
    "    s = Y.shape\n",
    "    \n",
    "    for i in range(0,s[0]): #跑每個timestamps\n",
    "        arr = np.where(Y[i]==1) #尋找這個timestamp 哪些label是ture\n",
    "        temp = []\n",
    "        for j in arr[0]:\n",
    "            temp.append(label_names[j]) #將這個timestamp true的label name拼成list\n",
    "        label_pair.loc[timestamps[i], 'Label Name'] = temp #把list放進對應的dataframe位置\n",
    "        \n",
    "    \n",
    "    new_label = []\n",
    "    new_index = []\n",
    "    for index in label_pair.index:\n",
    "        label = label_pair.loc[index].values[0]\n",
    "        if bool(label) == True:\n",
    "            for num,status in enumerate(main_label_list):\n",
    "                if bool(set(status) & set(label)):\n",
    "                    new_label.append(num)\n",
    "                    new_index.append(index)\n",
    "                    break\n",
    "                elif bool(set(label) & set(all_label_list)):\n",
    "                    continue\n",
    "                else:\n",
    "                    new_label.append(new_label_dict['Normal'])\n",
    "                    new_index.append(index)\n",
    "                    break\n",
    "\n",
    "    muti_index = pd.MultiIndex.from_product([[uuid], new_index], names=['uuid','timestamps'])\n",
    "    new_label = pd.DataFrame(data = new_label, index = muti_index,columns = ['Status'])\n",
    "    new_label_data = pd.concat([new_label_data,new_label],axis=0,ignore_index=False)\n",
    "\n",
    "    \n",
    "new_label_data.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fedc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine cleaned X and new Y\n",
    "Final_data = pd.concat([cleaned_data,new_label_data], axis=1, join='inner')\n",
    "\n",
    "def TS_data(ts, lag, n_ahead, target_index=-1):\n",
    "    \"\"\"\n",
    "    A method to create X and Y matrix from a time series array for the training of Time series model\n",
    "    Input:\n",
    "    ts should be np.array\n",
    "    lag is number of lags (timestamps back) to use for models\n",
    "    n_ahead is steps ahead to forecast\n",
    "    \n",
    "    Output is tuple\n",
    "    \"\"\"\n",
    "    # Extracting the number of features that are passed from the array \n",
    "    n_features = ts.shape[1]\n",
    "    \n",
    "    # Creating placeholder lists\n",
    "    X, Y = [], []\n",
    "\n",
    "    if len(ts) - lag <= 0:\n",
    "        X.append(ts)\n",
    "    else:\n",
    "        for i in range(len(ts) - lag - n_ahead):\n",
    "            Y.append(ts[(i + lag):(i + lag + n_ahead), target_index])\n",
    "            X.append(ts[i:(i + lag)])\n",
    "\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "\n",
    "    # Reshaping the X array to an RNN input shape \n",
    "    X = np.reshape(X, (X.shape[0], lag, n_features))\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def TS_split(Final_data, lag, n_ahead):\n",
    "    import random\n",
    "    with gzip.open('cleaned_data.zip','rb') as data:\n",
    "        data = pd.read_csv(data,index_col=[0,1])\n",
    "    idlist = data.groupby('uuid').count().index\n",
    "\n",
    "    random.seed(505)\n",
    "    randid = random.sample(list(range(0,len(idlist))), len(idlist))\n",
    "\n",
    "    train_data = pd.DataFrame()\n",
    "    validation_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "\n",
    "    for i in randid[0:38]:\n",
    "        train_data = pd.concat([train_data, Final_data.loc[idlist[i]]], axis = 0)\n",
    "        \n",
    "    for i in randid[38:45]:\n",
    "        validation_data = pd.concat([validation_data, Final_data.loc[idlist[i]]], axis = 0)\n",
    "\n",
    "    for i in randid[45:]:\n",
    "        test_data = pd.concat([test_data, Final_data.loc[idlist[i]]], axis = 0)\n",
    "    \n",
    "    \n",
    "    x_train, y_train = TS_data(train_data.values, lag, n_ahead)\n",
    "    \n",
    "    x_val, y_val = TS_data(validation_data.values, lag, n_ahead)\n",
    "    \n",
    "    x_test, y_test = TS_data(test_data.values, lag, n_ahead)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test  = TS_split(Final_data, lag=3, n_ahead=1)\n",
    "\n",
    "print(f\"Shape of training X: {x_train.shape}\")\n",
    "print(f\"Shape of the training Y data: {y_train.shape}\")\n",
    "\n",
    "print(f\"Shape of validation X: {x_val.shape}\")\n",
    "print(f\"Shape of the validation Y data: {y_val.shape}\")\n",
    "\n",
    "print(f\"Shape of testing X: {x_test.shape}\")\n",
    "print(f\"Shape of the testing Y: {y_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
