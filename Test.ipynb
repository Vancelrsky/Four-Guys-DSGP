{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%run MyNoteBook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Functions\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status\n",
       "6         101953\n",
       "0          76282\n",
       "4          54441\n",
       "1          52496\n",
       "2          21894\n",
       "3          17090\n",
       "5           9891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('cleaned_data.zip','rb') as data:\n",
    "    data = pd.read_csv(data,index_col=[0,1])\n",
    "\n",
    "resting = ['SLEEPING','LYING_DOWN']\n",
    "\n",
    "\n",
    "phone_state = ['PHONE_IN_POCKET','PHONE_IN_HAND', 'PHONE_IN_BAG', 'PHONE_ON_TABLE']\n",
    "body_state = ['SITTING','FIX_walking', 'FIX_running', 'OR_standing']\n",
    "loc_state = ['OR_indoors', 'OR_outside', 'LOC_home', 'LOC_main_workplace','AT_SCHOOL','IN_A_CAR', 'ON_A_BUS']\n",
    "focus = ['LAB_WORK', 'IN_CLASS', 'IN_A_MEETING','COMPUTER_WORK', 'WITH_CO-WORKERS', 'DRIVE_-_I_M_THE_DRIVER','TALKING']\n",
    "\n",
    "housekeeping = ['COOKING', 'BATHING_-_SHOWER', 'CLEANING', 'DOING_LAUNDRY', 'WASHING_DISHES', 'EATING', 'TOILET', 'GROOMING', 'DRESSING']\n",
    "exercising = ['BICYCLING','OR_exercise','STAIRS_-_GOING_UP','STAIRS_-_GOING_DOWN', 'ELEVATOR']\n",
    "quiet_entertainment = ['FIX_restaurant','WATCHING_TV', 'SURFING_THE_INTERNET', 'LOC_beach','WITH_FRIENDS','DRIVE_-_I_M_A_PASSENGER']\n",
    "busy_entertainment = ['SHOPPING', 'STROLLING', 'DRINKING__ALCOHOL_', 'AT_A_PARTY', 'AT_A_BAR','SINGING']\n",
    "main_label_list = []\n",
    "\n",
    "new_label_list = ['sleep','entertainment','exercise','life_activity','efficiency','on_the_way']\n",
    "new_label_dict = {'sleep':0,'entertainment':1,'exercise':2,'life_activity':3,'efficiency':4,'on_the_way':5,'Normal':6}\n",
    "all_label_list = []\n",
    "\n",
    "for i in main_label_list:\n",
    "    all_label_list = all_label_list + i\n",
    "\n",
    "new_label_data = pd.DataFrame()\n",
    "for uuid in data.groupby('uuid').count().index:\n",
    "    X,Y,M,timestamps,feature_names,label_names = Functions.read_user_data(uuid)\n",
    "    label_pair = pd.DataFrame(\n",
    "        columns = ['Label Name'],\n",
    "        index = timestamps\n",
    "    )\n",
    "    s = Y.shape\n",
    "\n",
    "\n",
    "    for i in range(0,s[0]): #跑每個timestamps\n",
    "        arr = np.where(Y[i]==1) #尋找這個timestamp 哪些label是ture\n",
    "        temp = []\n",
    "        for j in arr[0]:\n",
    "            temp.append(label_names[j]) #將這個timestamp true的label name拼成list\n",
    "        label_pair.loc[timestamps[i], 'Label Name'] = temp #把list放進對應的dataframe位置\n",
    "\n",
    "    new_label = []\n",
    "    for index in range(len(label_pair.index)):\n",
    "        label = label_pair.iloc[index].values[0]\n",
    "        print(label)\n",
    "        break\n",
    "        for num,status in enumerate(main_label_list):\n",
    "            if bool(set(status) & set(label)):\n",
    "                new_label.append(num)\n",
    "                break\n",
    "            elif bool(set(label) & set(all_label_list)):\n",
    "                continue\n",
    "            else:\n",
    "                new_label.append(new_label_dict['Normal'])\n",
    "                break\n",
    "\n",
    "    #muti_index = pd.MultiIndex.from_product([[uuid], X.index], names=['uuid','timestamps'])\n",
    "    #new_label = pd.DataFrame(data = new_label, index = muti_index,columns = ['Status'])\n",
    "    #new_label_data = pd.concat([new_label_data,new_label],axis=0,ignore_index=False)\n",
    "\n",
    "new_label_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open('cleaned_data.zip','rb') as data:\n",
    "    data = pd.read_csv(data,index_col=[0,1])\n",
    "len(data.groupby('uuid').count().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_label_list = [['SLEEPING'],\n",
    "                   ['FIX_restaurant','SHOPPING', 'STROLLING', 'DRINKING__ALCOHOL_','WATCHING_TV', 'SURFING_THE_INTERNET', 'AT_A_PARTY', 'AT_A_BAR', 'LOC_beach', 'SINGING', 'WITH_FRIENDS'],\n",
    "                   ['FIX_walking', 'FIX_running', 'BICYCLING','OR_exercise'],\n",
    "                   ['COOKING', 'BATHING_-_SHOWER', 'CLEANING', 'DOING_LAUNDRY', 'WASHING_DISHES', 'EATING', 'TOILET', 'GROOMING', 'DRESSING'],\n",
    "                   ['LAB_WORK', 'IN_CLASS', 'IN_A_MEETING', 'LOC_main_workplace','COMPUTER_WORK','AT_SCHOOL', 'WITH_CO-WORKERS'],\n",
    "                   ['IN_A_CAR', 'ON_A_BUS', 'DRIVE_-_I_M_THE_DRIVER', 'DRIVE_-_I_M_A_PASSENGER','STAIRS_-_GOING_DOWN', 'ELEVATOR']]\n",
    "new_label_list = ['sleep','entertainment','exercise','life_activity','efficiency','on_the_way']\n",
    "new_label_dict = {'sleep':0,'entertainment':1,'exercise':2,'life_activity':3,'efficiency':4,'on_the_way':5,'Normal':6}\n",
    "all_label_list = []\n",
    "\n",
    "for i in main_label_list:\n",
    "    all_label_list = all_label_list + i\n",
    "uuid_list = list(data.groupby('uuid').count().index)\n",
    "new_label_data = pd.DataFrame()\n",
    "for uuid in [uuid_list[0]]:\n",
    "    X,Y,M,timestamps,feature_names,label_names = Functions.read_user_data(uuid)\n",
    "    label_pair = pd.DataFrame(\n",
    "        columns = ['Label Name'],\n",
    "        index = timestamps\n",
    "    )\n",
    "    s = Y.shape\n",
    "\n",
    "\n",
    "    for i in range(0,s[0]): #跑每個timestamps\n",
    "        arr = np.where(Y[i]==1) #尋找這個timestamp 哪些label是ture\n",
    "        temp = []\n",
    "        for j in arr[0]:\n",
    "            temp.append(label_names[j]) #將這個timestamp true的label name拼成list\n",
    "        label_pair.loc[timestamps[i], 'Label Name'] = temp #把list放進對應的dataframe位置\n",
    "    new_label = []\n",
    "\n",
    "    for index in label_pair.index:\n",
    "        label = label_pair.loc[index].values[0]\n",
    "        if bool(label) == True:\n",
    "            for num,status in enumerate(main_label_list):\n",
    "                if bool(set(status) & set(label)):\n",
    "                    new_label.append(num)\n",
    "                    break\n",
    "                elif bool(set(label) & set(all_label_list)):\n",
    "                    continue\n",
    "                else:\n",
    "                    new_label.append(new_label_dict['Normal'])\n",
    "                    break \n",
    "\n",
    "    #muti_index = pd.MultiIndex.from_product([[uuid], X.index], names=['uuid','timestamps'])\n",
    "    #new_label = pd.DataFrame(data = new_label, index = muti_index,columns = ['Status'])\n",
    "    #new_label_data = pd.concat([new_label_data,new_label],axis=0,ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train,columns=data.iloc[:,:-1].columns)\n",
    "X_test = pd.DataFrame(X_test,columns=data.iloc[:,:-1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_to_data(csv_df,n):\n",
    "\n",
    "    pca = PCA(n_components=n)\n",
    "    features = csv_df.loc[:,csv_df.columns.str.startswith('audio_naive')]\n",
    "    new_features = pca.fit_transform(features)\n",
    "    pca_components = pca.components_\n",
    "\n",
    "    print('PCA explained variance ratio is', pca.explained_variance_ratio_.sum())\n",
    "\n",
    "    new_feature_df = pd.DataFrame(data=new_features,index=csv_df.index,columns=['audio_naive:pc1','audio_naive:pc2'])\n",
    "    other_features = csv_df.loc[:,(csv_df.columns.str.startswith('audio_naive') == False)]\n",
    "    new_feature_df = pd.concat([other_features,new_feature_df],axis=1,ignore_index=False)\n",
    "\n",
    "\n",
    "    return (new_feature_df, pca_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_to_train_test(X_train, X_test):\n",
    "    X_train = pd.DataFrame(X_train,columns=data.iloc[:,:-1].columns)\n",
    "    X_test = pd.DataFrame(X_test,columns=data.iloc[:,:-1].columns)\n",
    "    X_train_pca, projection = pca_to_data(X_train,2)\n",
    "\n",
    "    audio_test = X_test.loc[:,X_test.columns.str.startswith('audio_naive')]\n",
    "    X_test_pca = X_test.loc[:,X_test.columns.str.startswith('audio_naive')==False]\n",
    "    projection_matrix = pd.DataFrame(np.dot(audio_test,projection.T),columns=['audio_naive:pc1','audio_naive:pc2'])\n",
    "    X_test_pca = pd.concat([X_test_pca,projection_matrix],axis=1)\n",
    "    return X_train_pca.values, X_test_pca.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA explained variance ratio is 0.9451129086197556\n",
      "(233244, 39)\n",
      "(58311, 39)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "with gzip.open('cleaned_data.zip','rb') as file:\n",
    "    feature_data = pd.read_csv(file,index_col=[0,1])\n",
    "\n",
    "with gzip.open('new_label_data.zip','rb') as file:\n",
    "    new_label_data = pd.read_csv(file,index_col=[0,1])\n",
    "\n",
    "data = pd.concat([feature_data,new_label_data],join='inner',ignore_index=False,axis=1)\n",
    "X = data.iloc[:,:-1].values\n",
    "Y = data.iloc[:,-1].values\n",
    "# split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size= 0.2, random_state = 52)\n",
    "X_train, X_test = Functions.pca_to_train_test(X_train,X_test,data)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_dict = {}\n",
    "for key in label_pair.values:\n",
    "    l_dict[key] = l_dict.get(key, 0) + 1\n",
    "l_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SITTING': 99,\n",
       " 'LOC_main_workplace': 153,\n",
       " 'COMPUTER_WORK': 167,\n",
       " 'FIX_walking': 12,\n",
       " 'OR_indoors': 19,\n",
       " 'TOILET': 10,\n",
       " 'OR_standing': 56,\n",
       " 'LOC_home': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Functions.get_related_label('COMPUTER_WORK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SITTING': 757,\n",
       " 'LOC_main_workplace': 365,\n",
       " 'COMPUTER_WORK': 99,\n",
       " 'TALKING': 60,\n",
       " 'EATING': 113,\n",
       " 'OR_indoors': 92,\n",
       " 'LOC_home': 92,\n",
       " 'SURFING_THE_INTERNET': 11,\n",
       " 'WATCHING_TV': 20,\n",
       " 'DRESSING': 10,\n",
       " 'IN_A_MEETING': 138,\n",
       " 'IN_A_CAR': 45,\n",
       " 'PHONE_IN_BAG': 30}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status                \n",
       "SITTING                   119500\n",
       "LYING_DOWN                 93798\n",
       "None                       42492\n",
       "FIX_walking                20272\n",
       "OR_indoors                 16367\n",
       "LOC_home                   13427\n",
       "LOC_main_workplace          7892\n",
       "BICYCLING                   4741\n",
       "OR_standing                 4368\n",
       "OR_outside                  1749\n",
       "PHONE_IN_POCKET             1516\n",
       "LAB_WORK                    1300\n",
       "FIX_running                 1073\n",
       "TALKING                      737\n",
       "COOKING                      673\n",
       "AT_A_PARTY                   546\n",
       "IN_A_MEETING                 520\n",
       "OR_exercise                  489\n",
       "DRINKING__ALCOHOL_           430\n",
       "IN_CLASS                     239\n",
       "LOC_beach                    232\n",
       "SLEEPING                     185\n",
       "COMPUTER_WORK                180\n",
       "GROOMING                     157\n",
       "FIX_restaurant               149\n",
       "CLEANING                     142\n",
       "IN_A_CAR                     136\n",
       "ON_A_BUS                     134\n",
       "SURFING_THE_INTERNET         120\n",
       "SHOPPING                     110\n",
       "WASHING_DISHES                92\n",
       "WATCHING_TV                   82\n",
       "DRESSING                      80\n",
       "EATING                        38\n",
       "PHONE_ON_TABLE                27\n",
       "DRIVE_-_I_M_THE_DRIVER        27\n",
       "DOING_LAUNDRY                 13\n",
       "PHONE_IN_HAND                  7\n",
       "PHONE_IN_BAG                   5\n",
       "TOILET                         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('cleaned_data.zip','rb') as file:\n",
    "    feature_data = pd.read_csv(file,index_col=[0,1])\n",
    "# split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(feature_data,new_label_data,test_size= 0.2, random_state = 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              objective='multi:softprob', predictor=None, ...)\n"
     ]
    }
   ],
   "source": [
    "# fit model \n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.03%\n"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "Y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in Y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
