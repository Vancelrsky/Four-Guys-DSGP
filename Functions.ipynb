{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"c2cb0c7e8200406a881d3dc3767746da","deepnote_cell_type":"code","tags":[]},"outputs":[],"source":["import numpy as np\n","import gzip\n","import pandas as pd\n","from sklearn.impute import KNNImputer \n","import os\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"fa035ad5e5004cf7aab2596197cdbe4f","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":17,"execution_start":1678558847248,"is_code_hidden":true,"source_hash":"661092f9","tags":[]},"outputs":[],"source":["# this method take a dataframe as input, return the feature part and label part\n","def parse_header_of_csv(csv_df):\n","    # Isolate the headline columns:\n","\n","    for (ci,col) in enumerate(csv_df.columns):\n","        # find the start of label column\n","            if col.startswith('label:'):\n","                first_label_ind = ci\n","                break\n","            pass\n","    # use the \"start of label\" find above to split feature and label\n","    feature_names = csv_df.columns[1:first_label_ind]\n","    label_names = list(csv_df.columns[first_label_ind:-1])\n","\n","    # remove \"label: \" get pure label name\n","    for (li,label) in enumerate(label_names):\n","    # In the CSV the label names appear with prefix 'label:', but we don't need it after reading the data:\n","            assert label.startswith('label:')\n","            label_names[li] = label.replace('label:','')\n","            pass\n","\n","    csv_df.rename(columns=dict(zip(csv_df.columns[first_label_ind:-1],label_names)),inplace=True)\n","        \n","    return (feature_names,label_names)\n","\n","\"\"\"\n","this method take a dataframe and number of features as input, \n","return sensor matrix, label matrix, missing label matrix and timestamp matrix(index)\n","\"\"\"\n","def parse_body_of_csv(csv_df,n_features):\n","\n","\n","    # Read the entire CSV body into a single numeric matrix:\n","    \n","    # Timestamp is the primary key for the records (examples):\n","    timestamps = csv_df.index\n","    # Read the sensor features:\n","    X = csv_df[csv_df.columns[0:n_features+1]]\n","    # Read the binary label values, and the 'missing label' indicators:\n","    trinary_labels_mat = csv_df[csv_df.columns[n_features+1:-1]] # This should have values of either 0., 1. or NaN\n","\n","    M = pd.isna(trinary_labels_mat) # M is the missing label matrix\n","    Y = np.where(M,0,trinary_labels_mat) > 0. # Y is the label matrix\n","\n","    \n","    return (X,Y,M,timestamps)\n","\n","'''\n","Read the data (precomputed sensor-features and labels) for a user.\n","This function assumes the user's data file is present.\n","this method take id of subject as input\n","return sensor matrix, label matrix, missing label matrix and timestamp matrix(index) by calling parse_body_of_csv()method\n","\n","'''\n","def read_user_data(uuid):\n","    user_data_file = 'Datasets/%s.features_labels.csv.gz' % uuid\n","\n","    with gzip.open(user_data_file,'rb') as fid:\n","        csv_df = pd.read_csv(fid,delimiter=',', index_col= 0)\n","        pass\n","\n","    (feature_names,label_names) = parse_header_of_csv(csv_df)\n","    n_features = len(feature_names)\n","    (X,Y,M,timestamps) = parse_body_of_csv(csv_df,n_features)\n","\n","    return (X,Y,M,timestamps,feature_names,label_names)\n","\n","#To create uuid_list which includes all uuid\n","uuid_list = []\n","f = open('UUID List.txt', 'r')\n","for line in f.readlines():\n","    uuid_list.append(line.strip())\n","\n","# To create main feature list\n","    main_feature = []\n","    f = open('Main Feature.txt', 'r')\n","    for line in f.readlines():\n","        main_feature.append(line.strip())\n","\n","\"\"\"\n","by calling this method we can get a list of dataframe which contain all the user's sensor data\n","//3.6 v0 may get label lists later w.\n","Author chen\n","\"\"\"\n","def get_df_list():\n","    #To create uuid_list which includes all uuid\n","    uuid_list = []\n","    f = open('UUID List.txt', 'r')\n","    for line in f.readlines():\n","        uuid_list.append(line.strip())\n","\n","    main_feature = []\n","    f = open('Main Feature.txt', 'r')\n","    for line in f.readlines():\n","        main_feature.append(line.strip())\n","\n","    instance = []\n","    # Run all uuid\n","    for i in range(len(uuid_list)):    \n","        (X,Y,M,timestamps,feature_names,label_names) = read_user_data(uuid_list[i])\n","\n","        # Create dataframe for all Main Feature value\n","        Main_X = pd.DataFrame(X.loc[:,X.columns.str.startswith(main_feature[0])], columns = [main_feature[0]])\n","        for j in range(1,len(main_feature)):\n","            Main_X = pd.concat([Main_X, X.loc[:,X.columns.str.startswith(main_feature[j])]], axis=1)\n","        instance.append(Main_X)\n","    return instance\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def get_df(uuid):\n","    main_feature = []\n","    f = open('Main Feature.txt', 'r')\n","    for line in f.readlines():\n","        main_feature.append(line.strip())\n","\n","    # Run all uuid \n","    (X,Y,M,timestamps,feature_names,label_names) = read_user_data(uuid)\n","\n","    # Create dataframe for all Main Feature value\n","    Main_X = pd.DataFrame(X.loc[:,X.columns.str.startswith(main_feature[0])], columns = [main_feature[0]])\n","    for j in range(1,len(main_feature)):\n","        Main_X = pd.concat([Main_X, X.loc[:,X.columns.str.startswith(main_feature[j])]], axis=1)\n","    return Main_X"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"4f44bc4c135b4197af3feb42962c9753","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1678559608267,"source_hash":"2f1beb45","tags":[]},"outputs":[],"source":["# 用均值补除了手表的数据\n","def non_watch_value_imputer(df):\n","    # get the data except watch\n","    non_watch_values = df.loc[:,(df.columns.str.startswith('watch_') == False)]\n","    valid_data = pd.DataFrame(columns = ['blank'])\n","    # use mean values to fill the none value\n","    for column in non_watch_values.columns:\n","        column_df = non_watch_values[column]\n","        mean_value = non_watch_values[column].mean()\n","        column_df = column_df.fillna(mean_value)\n","        valid_data = pd.concat([valid_data, column_df],axis=1,ignore_index=False)\n","\n","    valid_data = valid_data[valid_data.columns[1:]]\n","    #combine the watch data\n","    combine_data = pd.concat([valid_data,df.loc[:,df.columns.str.startswith('watch_')]],axis=1,ignore_index=False)\n","    return combine_data\n","# 用其他传感器数据的KNN补手表数据\n","def KNN_for_watch_data(df,K):\n","    #input data and K neighbors\n","    imputer = KNNImputer(n_neighbors=K)\n","    df[list(df.columns)] = imputer.fit_transform(df)\n","    return df "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def get_cross_validation(type, folds_num):\n","    # 输入type与folds_num, 返回uuid_list\n","    uuid = []\n","    for fold in os.listdir('Splitted_folds'):\n","        if  folds_num == int(fold.split('_')[1]) and str(type).lower() == fold.split('_')[2].lower():\n","            uuid_list = open(\"Splitted_folds/%s\" % fold, 'r')\n","            fold_uuid_list = uuid_list.read().split()\n","            uuid = uuid + fold_uuid_list\n","    return uuid"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def pca_to_data(csv_df,n):\n","\n","    pca = PCA(n_components=n)\n","    features = csv_df.loc[:,csv_df.columns.str.startswith('audio_naive')]\n","    new_features = pca.fit_transform(features)\n","    pca_components = pca.components_\n","\n","    print('PCA explained variance ratio is', pca.explained_variance_ratio_.sum())\n","\n","    new_feature_df = pd.DataFrame(data=new_features,index=csv_df.index,columns=['audio_naive:pc1','audio_naive:pc2'])\n","    other_features = csv_df.loc[:,(csv_df.columns.str.startswith('audio_naive') == False)]\n","    new_feature_df = pd.concat([other_features,new_feature_df],axis=1,ignore_index=False)\n","\n","\n","    return (new_feature_df, pca_components)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def get_related_label(char):\n","    with gzip.open('cleaned_data.zip','rb') as data:\n","        data = pd.read_csv(data,index_col=[0,1])\n","    new_label_data = []\n","    for uuid in data.groupby('uuid').count().index:\n","        X,Y,M,timestamps,feature_names,label_names = read_user_data(uuid)\n","        label_dict = {v: k for k, v in dict(enumerate(label_names + ['None'])).items()}\n","        label_list = []\n","        for each in Y:\n","            if np.array(each).any()==False:\n","                continue\n","            else:\n","                new_label_names = np.array(label_names)[each]\n","                if char in new_label_names:\n","                    label_list.append(list(new_label_names))\n","    new_label_data = new_label_data + label_list\n","    labels = []\n","    for i in new_label_data:\n","        labels = labels + i\n","    l_dict = {}\n","    for key in labels:\n","        l_dict[key] = l_dict.get(key, 0) + 1\n","    return l_dict\n","\n"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"e468f09dbfc841748c0128e3085d0070","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.4"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
