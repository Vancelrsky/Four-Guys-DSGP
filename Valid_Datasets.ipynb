{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"c2cb0c7e8200406a881d3dc3767746da","deepnote_cell_type":"code","tags":[]},"outputs":[],"source":["import numpy as np\n","import gzip\n","import pandas as pd\n","from sklearn.impute import KNNImputer \n","import os"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"fa035ad5e5004cf7aab2596197cdbe4f","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":17,"execution_start":1678558847248,"is_code_hidden":true,"source_hash":"661092f9","tags":[]},"outputs":[],"source":["# this method take a dataframe as input, return the feature part and label part\n","def parse_header_of_csv(csv_df):\n","    # Isolate the headline columns:\n","\n","    for (ci,col) in enumerate(csv_df.columns):\n","        # find the start of label column\n","            if col.startswith('label:'):\n","                first_label_ind = ci\n","                break\n","            pass\n","    # use the \"start of label\" find above to split feature and label\n","    feature_names = csv_df.columns[1:first_label_ind]\n","    label_names = list(csv_df.columns[first_label_ind:-1])\n","\n","    # remove \"label: \" get pure label name\n","    for (li,label) in enumerate(label_names):\n","    # In the CSV the label names appear with prefix 'label:', but we don't need it after reading the data:\n","            assert label.startswith('label:')\n","            label_names[li] = label.replace('label:','')\n","            pass\n","\n","    csv_df.rename(columns=dict(zip(csv_df.columns[first_label_ind:-1],label_names)),inplace=True)\n","        \n","    return (feature_names,label_names)\n","\n","\"\"\"\n","this method take a dataframe and number of features as input, \n","return sensor matrix, label matrix, missing label matrix and timestamp matrix(index)\n","\"\"\"\n","def parse_body_of_csv(csv_df,n_features):\n","\n","\n","    # Read the entire CSV body into a single numeric matrix:\n","    \n","    # Timestamp is the primary key for the records (examples):\n","    timestamps = csv_df.index\n","    # Read the sensor features:\n","    X = csv_df[csv_df.columns[0:n_features+1]]\n","    # Read the binary label values, and the 'missing label' indicators:\n","    trinary_labels_mat = csv_df[csv_df.columns[n_features+1:-1]] # This should have values of either 0., 1. or NaN\n","\n","    M = pd.isna(trinary_labels_mat) # M is the missing label matrix\n","    Y = np.where(M,0,trinary_labels_mat) > 0. # Y is the label matrix\n","\n","    \n","    return (X,Y,M,timestamps)\n","\n","'''\n","Read the data (precomputed sensor-features and labels) for a user.\n","This function assumes the user's data file is present.\n","this method take id of subject as input\n","return sensor matrix, label matrix, missing label matrix and timestamp matrix(index) by calling parse_body_of_csv()method\n","\n","'''\n","def read_user_data(uuid):\n","    user_data_file = 'Datasets/%s.features_labels.csv.gz' % uuid\n","\n","    with gzip.open(user_data_file,'rb') as fid:\n","        csv_df = pd.read_csv(fid,delimiter=',', index_col= 0)\n","        pass\n","\n","    (feature_names,label_names) = parse_header_of_csv(csv_df)\n","    n_features = len(feature_names)\n","    (X,Y,M,timestamps) = parse_body_of_csv(csv_df,n_features)\n","\n","    return (X,Y,M,timestamps,feature_names,label_names)\n","\n","#To create uuid_list which includes all uuid\n","uuid_list = []\n","f = open('UUID List.txt', 'r')\n","for line in f.readlines():\n","    uuid_list.append(line.strip())\n","\n","# To create main feature list\n","    main_feature = []\n","    f = open('Main Feature.txt', 'r')\n","    for line in f.readlines():\n","        main_feature.append(line.strip())\n","\n","\"\"\"\n","by calling this method we can get a list of dataframe which contain all the user's sensor data\n","//3.6 v0 may get label lists later w.\n","Author chen\n","\"\"\"\n","def get_df_list(uuid_list):\n","    #To create uuid_list which includes all uuid\n","    \"\"\" uuid_list = []\n","    f = open('UUID List.txt', 'r')\n","    for line in f.readlines():\n","        uuid_list.append(line.strip()) \"\"\"\n","\n","    main_feature = []\n","    f = open('Main Feature.txt', 'r')\n","    for line in f.readlines():\n","        main_feature.append(line.strip())\n","\n","    instance = []\n","    # Run all uuid\n","    for i in range(len(uuid_list)):    \n","        (X,Y,M,timestamps,feature_names,label_names) = read_user_data(uuid_list[i])\n","\n","        # Create dataframe for all Main Feature value\n","        Main_X = pd.DataFrame(X.loc[:,X.columns.str.startswith(main_feature[0])], columns = [main_feature[0]])\n","        for j in range(1,len(main_feature)):\n","            Main_X = pd.concat([Main_X, X.loc[:,X.columns.str.startswith(main_feature[j])]], axis=1)\n","        instance.append(Main_X)\n","    return instance \n"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"4f44bc4c135b4197af3feb42962c9753","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1678559608267,"source_hash":"2f1beb45","tags":[]},"outputs":[],"source":["# 用均值补除了手表的数据\n","def non_watch_value_imputer(df):\n","    # get the data except watch\n","    non_watch_values = df.loc[:,(df.columns.str.startswith('watch_') == False)]\n","    valid_data = pd.DataFrame(columns = ['blank'])\n","    # use mean values to fill the none value\n","    for column in non_watch_values.columns:\n","        column_df = non_watch_values[column]\n","        mean_value = non_watch_values[column].mean()\n","        column_df = column_df.fillna(mean_value)\n","        valid_data = pd.concat([valid_data, column_df],axis=1,ignore_index=False)\n","\n","    valid_data = valid_data[valid_data.columns[1:]]\n","    #combine the watch data\n","    combine_data = pd.concat([valid_data,df.loc[:,df.columns.str.startswith('watch_')]],axis=1,ignore_index=False)\n","    return combine_data\n","# 用其他传感器数据的KNN补手表数据\n","def KNN_for_watch_data(df,K):\n","    #input data and K neighbors\n","    imputer = KNNImputer(n_neighbors=K)\n","    df[list(df.columns)] = imputer.fit_transform(df)\n","    return df "]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def get_cross_validation(type, folds_num):\n","    # 输入type与folds_num, 返回uuid_list\n","    uuid = []\n","    for fold in os.listdir('Splitted_folds'):\n","        if  folds_num == int(fold.split('_')[1]) and str(type).lower() == fold.split('_')[2].lower():\n","            uuid_list = open(\"Splitted_folds/%s\" % fold, 'r')\n","            fold_uuid_list = uuid_list.read().split()\n","            uuid = uuid + fold_uuid_list\n","    return uuid"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown","tags":[]},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=51389dd1-61f3-47fa-93db-d3cd8b3bb8b3' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"e468f09dbfc841748c0128e3085d0070","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.4"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
